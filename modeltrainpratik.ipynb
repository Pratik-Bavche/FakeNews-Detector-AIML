{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd import numpy as np import re import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split from\n",
    "sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline from sklearn.linear_model import\n",
    "LogisticRegression from sklearn.metrics import accuracy_score import\n",
    "joblib\n",
    "\n",
    "# For Text Cleaning\n",
    "\n",
    "def clean_text(text): text = text.lower() text = re.sub(’\\[.*?\\]‘,’’,\n",
    "text) text = re.sub(“https?://+\\|www.+”, ““, text) text =\n",
    "re.sub(”\\<.*?\\>+“,”“, text) text = re.sub(”\\[%s\\]” %\n",
    "re.escape(string.punctuation), ““, text) text = re.sub(”“,” “, text)\n",
    "text = re.sub(”“,”“, text) return text\n",
    "\n",
    "# Load Dataset 1\n",
    "\n",
    "true_news = pd.read_csv(“D:/FakeNews-Detector-AIML/true_news.csv”)\n",
    "true_news\\[“label”\\] = 1 true_news\\[“Article”\\] =\n",
    "true_news\\[“title”\\].astype(str) + ” ” + true_news\\[“text”\\].astype(str)\n",
    "true_news = true_news.loc\\[:, \\[“Article”, “label”\\]\\]\n",
    "\n",
    "# Load Dataset 2\n",
    "\n",
    "false_news = pd.read_csv(“D:/FakeNews-Detector-AIML/false_news.csv”)\n",
    "false_news\\[“label”\\] = 0 false_news\\[“Article”\\] =\n",
    "false_news\\[“title”\\].astype(str) + ” ” +\n",
    "false_news\\[“text”\\].astype(str) false_news = false_news.loc\\[:,\n",
    "\\[“Article”, “label”\\]\\]\n",
    "\n",
    "# Load Dataset 3\n",
    "\n",
    "data3 = pd.read_csv(“D:/FakeNews-Detector-AIML/data.csv”)\n",
    "data3\\[“Article”\\] = data3\\[“Headline”\\].astype(str) + ” ” +\n",
    "data3\\[“Body”\\].astype(str) data3\\[“label”\\] = data3\\[“Label”\\] data3 =\n",
    "data3.loc\\[:, \\[“Article”, “label”\\]\\]\n",
    "\n",
    "# Combine All Datasets\n",
    "\n",
    "Dataset = pd.concat(\\[true_news, false_news, data3\\],\n",
    "ignore_index=True).dropna()\n",
    "\n",
    "# Clean text\n",
    "\n",
    "Dataset\\[“Article”\\] = Dataset\\[“Article”\\].apply(clean_text)\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "Dataset\\[“Article”\\], Dataset\\[“label”\\].astype(int), test_size=0.2,\n",
    "random_state=42 )\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "\n",
    "pipe = Pipeline(\\[ (“vect”, CountVectorizer()), (“tfidf”,\n",
    "TfidfTransformer()), (“model”, LogisticRegression(max_iter=300))\\])\n",
    "\n",
    "model = pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test) accuracy = round(accuracy_score(y_test,\n",
    "pred) \\* 100, 2) print(“Model Accuracy:”, accuracy, “%”)\n",
    "\n",
    "# Save Model\n",
    "\n",
    "joblib.dump(model, “D:/FakeNews-Detector-AIML/model.pkl”) print(“Model\n",
    "saved successfully!”)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
